{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dharma Setu Framework Demonstration\n",
    "\n",
    "\n",
    "\n",
    " This notebook demonstrates key components of the Dharma Setu framework, which bridges ancient Buddhist wisdom with modern AI technology.\n",
    "\n",
    "\n",
    "\n",
    " The framework implements several key components:\n",
    "\n",
    " 1. Core language models with cross-attention mechanisms\n",
    "\n",
    " 2. Cross-space alignment of Buddhist and contemporary concept spaces\n",
    "\n",
    " 3. Conceptual blending for generating new insights\n",
    "\n",
    " 4. Multimodal integration of different sensory channels\n",
    "\n",
    " 5. Digital Samayasattva/Jñānasattva framework for wisdom embodiment\n",
    "\n",
    " 6. Cross-traditional connections discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndharma_setu_demo.ipynb - Comprehensive demonstration of cross-domain knowledge integration techniques\\n\\nThis Jupyter notebook provides a practical demonstration of multiple machine learning techniques\\nfor cross-domain knowledge representation, integration, and analysis. The notebook serves as a\\nhands-on introduction to the implemented methods with small-scale examples suitable for\\ninteractive exploration.\\n\\nTechnical components demonstrated:\\n\\n1. Transformer-Based Attention Mechanisms:\\n   - Multi-head self-attention with scaled dot-product attention\\n   - Cross-domain attention for information transfer between different embedding spaces\\n   - Visualization of attention weights and information flow between domains\\n\\n2. Embedding Space Alignment:\\n   - Orthogonal Procrustes algorithm for finding optimal rotations between embedding spaces\\n   - Evaluation metrics for alignment quality (cosine similarity preservation)\\n   - Nearest neighbor search in aligned spaces for cross-domain concept mapping\\n\\n3. Vector Space Operations for Semantic Reasoning:\\n   - Analogical reasoning through vector arithmetic (A-B+C operation pattern)\\n   - Linear interpolation to explore semantic spaces between concepts\\n   - Implementation of top-k similarity search in normalized embedding spaces\\n\\n4. Multimodal Representation Learning:\\n   - Encoder architectures for different modalities (visual, text, audio)\\n   - Contrastive learning for aligning representations across modalities\\n   - Tensor fusion techniques for combining information from multiple sources\\n   - Demonstration of personalized content selection using Bayesian optimization\\n\\n5. Graph Neural Networks for Knowledge Graphs:\\n   - Graph Attention Network (GAT) implementation for node feature transformation\\n   - Demonstration of multi-head attention aggregation over graph neighborhoods\\n   - Visualization of how attention mechanisms modify node representations\\n\\n6. Spectral Graph Theory Applications:\\n   - Normalized graph Laplacian computation from weighted adjacency matrices\\n   - Spectral clustering for community detection in concept networks\\n   - Analysis and visualization of clusters spanning different categorical attributes\\n\\nThe notebook demonstrates how these techniques can be combined into an integrated framework\\nfor knowledge representation, transfer, and generation across domains. Each section includes\\ncode for creating and visualizing small example datasets, implementing the core algorithms,\\nand analyzing the results.\\n\\nFrom an implementation perspective, the notebook leverages TensorFlow for neural network\\ncomponents, NumPy for numerical operations, NetworkX for graph manipulation, scikit-learn\\nfor clustering algorithms, and Matplotlib for visualization.\\n\\nNote: While the examples use Buddhist terminology and concepts as a demonstration domain,\\nthe techniques implemented are standard machine learning approaches applicable to any\\nknowledge representation task requiring cross-domain integration.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dharma_setu_demo.ipynb - Comprehensive demonstration of cross-domain knowledge integration techniques\n",
    "\n",
    "This Jupyter notebook provides a practical demonstration of multiple machine learning techniques\n",
    "for cross-domain knowledge representation, integration, and analysis. The notebook serves as a\n",
    "hands-on introduction to the implemented methods with small-scale examples suitable for\n",
    "interactive exploration.\n",
    "\n",
    "Technical components demonstrated:\n",
    "\n",
    "1. Transformer-Based Attention Mechanisms:\n",
    "   - Multi-head self-attention with scaled dot-product attention\n",
    "   - Cross-domain attention for information transfer between different embedding spaces\n",
    "   - Visualization of attention weights and information flow between domains\n",
    "\n",
    "2. Embedding Space Alignment:\n",
    "   - Orthogonal Procrustes algorithm for finding optimal rotations between embedding spaces\n",
    "   - Evaluation metrics for alignment quality (cosine similarity preservation)\n",
    "   - Nearest neighbor search in aligned spaces for cross-domain concept mapping\n",
    "\n",
    "3. Vector Space Operations for Semantic Reasoning:\n",
    "   - Analogical reasoning through vector arithmetic (A-B+C operation pattern)\n",
    "   - Linear interpolation to explore semantic spaces between concepts\n",
    "   - Implementation of top-k similarity search in normalized embedding spaces\n",
    "\n",
    "4. Multimodal Representation Learning:\n",
    "   - Encoder architectures for different modalities (visual, text, audio)\n",
    "   - Contrastive learning for aligning representations across modalities\n",
    "   - Tensor fusion techniques for combining information from multiple sources\n",
    "   - Demonstration of personalized content selection using Bayesian optimization\n",
    "\n",
    "5. Graph Neural Networks for Knowledge Graphs:\n",
    "   - Graph Attention Network (GAT) implementation for node feature transformation\n",
    "   - Demonstration of multi-head attention aggregation over graph neighborhoods\n",
    "   - Visualization of how attention mechanisms modify node representations\n",
    "\n",
    "6. Spectral Graph Theory Applications:\n",
    "   - Normalized graph Laplacian computation from weighted adjacency matrices\n",
    "   - Spectral clustering for community detection in concept networks\n",
    "   - Analysis and visualization of clusters spanning different categorical attributes\n",
    "\n",
    "The notebook demonstrates how these techniques can be combined into an integrated framework\n",
    "for knowledge representation, transfer, and generation across domains. Each section includes\n",
    "code for creating and visualizing small example datasets, implementing the core algorithms,\n",
    "and analyzing the results.\n",
    "\n",
    "From an implementation perspective, the notebook leverages TensorFlow for neural network\n",
    "components, NumPy for numerical operations, NetworkX for graph manipulation, scikit-learn\n",
    "for clustering algorithms, and Matplotlib for visualization.\n",
    "\n",
    "Note: While the examples use Buddhist terminology and concepts as a demonstration domain,\n",
    "the techniques implemented are standard machine learning approaches applicable to any\n",
    "knowledge representation task requiring cross-domain integration.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 357) (cross_traditional_connections.py, line 357)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 14\u001b[1;36m\n\u001b[1;33m    from cross_traditional_connections import CrossTraditionalClusteringModel\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\DELL\\Documents\\Buddhism\\Contemporary Buddhism Article 2025\\cross_traditional_connections.py:357\u001b[1;36m\u001b[0m\n\u001b[1;33m    demonstrate_cross_traditional_connections()\"\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 357)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Import our modules\n",
    "from core_language_models import SelfAttention, CrossDomainAttention, BodhiSandhiIntegrationLayer\n",
    "from cross_space_alignment import OrthogonalProcrustes, ManhattanAlignment\n",
    "from conceptual_blending import ConceptualBlending\n",
    "from multimodal_integration import MultimodalIntegration, PersonalizedContentGenerator\n",
    "from digital_samayasattva import GraphAttentionLayer, DigitalSamayasattvaFramework\n",
    "from cross_traditional_connections import CrossTraditionalClusteringModel\n",
    "from utilities import load_pretrained_embeddings\n",
    "\n",
    "print(\"Imports successful. TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Core Language Models and Cross-Attention Mechanism\n",
    "\n",
    "\n",
    "\n",
    " The foundation of the Dharma Setu framework is the integration of Buddhist knowledge with general knowledge through cross-attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions for demonstration\n",
    "buddhist_dim = 256  # Embedding dimension for Buddhist LLM\n",
    "general_dim = 256   # Embedding dimension for general knowledge LLM\n",
    "output_dim = 256    # Output dimension\n",
    "batch_size = 4      # Batch size\n",
    "buddhist_seq_len = 16  # Sequence length for Buddhist text\n",
    "general_seq_len = 32   # Sequence length for general knowledge\n",
    "\n",
    "# Create random embeddings for demonstration\n",
    "buddhist_embeddings = tf.random.normal((batch_size, buddhist_seq_len, buddhist_dim))\n",
    "general_embeddings = tf.random.normal((batch_size, general_seq_len, general_dim))\n",
    "\n",
    "# Initialize the integration layer\n",
    "integration_layer = BodhiSandhiIntegrationLayer(\n",
    "    buddhist_dim=buddhist_dim,\n",
    "    general_dim=general_dim,\n",
    "    output_dim=output_dim\n",
    ")\n",
    "\n",
    "# Process the embeddings\n",
    "buddhist_output, general_output, attention_maps = integration_layer(\n",
    "    buddhist_embeddings, general_embeddings\n",
    ")\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Buddhist output shape: {buddhist_output.shape}\")\n",
    "print(f\"General output shape: {general_output.shape}\")\n",
    "print(f\"Buddhist->General attention shape: {attention_maps['b2g'].shape}\")\n",
    "print(f\"General->Buddhist attention shape: {attention_maps['g2b'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Cross-Space Alignment\n",
    "\n",
    "\n",
    "\n",
    " This section demonstrates how we can align Buddhist concept embeddings with contemporary concept embeddings, enabling knowledge transfer between these domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration purposes - simplified concept vectors\n",
    "buddhist_vectors = np.array([\n",
    "    [0.2, 0.5, 0.1, 0.8],  # emptiness (śūnyatā)\n",
    "    [0.3, 0.2, 0.7, 0.1],  # dependent origination (pratītyasamutpāda)\n",
    "    [0.9, 0.1, 0.3, 0.2]   # mindfulness (smṛti)\n",
    "], dtype=np.float32)\n",
    "\n",
    "contemporary_vectors = np.array([\n",
    "    [0.25, 0.45, 0.2, 0.7],  # non-essentialism\n",
    "    [0.35, 0.25, 0.6, 0.2],  # systems theory\n",
    "    [0.8, 0.15, 0.4, 0.3]    # present-moment awareness\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Orthogonal Procrustes alignment\n",
    "procrustes = OrthogonalProcrustes()\n",
    "W_procrustes, aligned_vectors_procrustes, avg_sim_procrustes = procrustes.align(\n",
    "    buddhist_vectors, contemporary_vectors\n",
    ")\n",
    "\n",
    "print(f\"Orthogonal Procrustes alignment average similarity: {avg_sim_procrustes:.4f}\")\n",
    "\n",
    "# Demonstrate transformation of a new Buddhist concept\n",
    "new_buddhist_concept = np.array([[0.4, 0.6, 0.2, 0.3]], dtype=np.float32)  # impermanence (anitya)\n",
    "transformed_procrustes = tf.matmul(new_buddhist_concept, W_procrustes, transpose_b=True)\n",
    "\n",
    "# Find nearest contemporary concepts\n",
    "print(\"\\nNearest contemporary concepts to transformed 'impermanence' (Procrustes):\")\n",
    "contemporary_concepts = [\"non-essentialism\", \"systems theory\", \"present-moment awareness\"]\n",
    "for i, vec in enumerate(contemporary_vectors):\n",
    "    similarity = np.dot(transformed_procrustes[0], vec) / (\n",
    "        np.linalg.norm(transformed_procrustes[0]) * np.linalg.norm(vec)\n",
    "    )\n",
    "    print(f\"  {contemporary_concepts[i]}: similarity = {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Conceptual Blending\n",
    "\n",
    "\n",
    "\n",
    " Conceptual blending enables the generation of novel insights at the intersection of Buddhist and contemporary knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample vocabularies\n",
    "buddhist_vocab = [\"emptiness\", \"impermanence\", \"non-self\", \"suffering\", \"compassion\"]\n",
    "contemporary_vocab = [\"quantum field\", \"process philosophy\", \"consciousness\", \"neuroplasticity\", \"empathy\"]\n",
    "\n",
    "# Create random embeddings for demonstration\n",
    "embedding_dim = 64\n",
    "buddhist_emb = tf.random.normal((len(buddhist_vocab), embedding_dim))\n",
    "contemporary_emb = tf.random.normal((len(contemporary_vocab), embedding_dim))\n",
    "\n",
    "# Create blending object\n",
    "blender = ConceptualBlending(buddhist_emb, contemporary_emb, buddhist_vocab, contemporary_vocab)\n",
    "\n",
    "# Analogical reasoning example\n",
    "# \"emptiness is to non-self as quantum field is to what?\"\n",
    "results = blender.analogical_reasoning(\"emptiness\", \"non-self\", \"quantum field\")\n",
    "print(\"Emptiness is to non-self as quantum field is to:\")\n",
    "for concept, similarity in results:\n",
    "    print(f\"  {concept} (similarity: {similarity:.4f})\")\n",
    "\n",
    "# Interpolation example\n",
    "# Create a spectrum between \"compassion\" and \"empathy\"\n",
    "interpolations = blender.concept_interpolation(\"compassion\", \"empathy\", steps=3)\n",
    "print(\"\\nInterpolation between compassion and empathy:\")\n",
    "for alpha, nearest in interpolations:\n",
    "    concept, similarity = nearest[0]  # Get top match\n",
    "    print(f\"  Alpha={alpha:.2f}: {concept} (similarity: {similarity:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Multimodal Integration\n",
    "\n",
    "\n",
    "\n",
    " This section demonstrates the integration of different modalities (visual, textual, audio) in a unified framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "visual_dim = 512  # e.g., from a CNN\n",
    "text_dim = 256    # e.g., from a language model\n",
    "audio_dim = 128   # e.g., from an audio encoder\n",
    "joint_dim = 384   # Dimension of joint embedding space\n",
    "batch_size = 4    # Batch size\n",
    "\n",
    "# Create random inputs for demonstration\n",
    "visual_input = tf.random.normal((batch_size, visual_dim))\n",
    "text_input = tf.random.normal((batch_size, text_dim))\n",
    "audio_input = tf.random.normal((batch_size, audio_dim))\n",
    "\n",
    "# Initialize the multimodal integration model\n",
    "model = MultimodalIntegration(\n",
    "    visual_dim=visual_dim,\n",
    "    text_dim=text_dim,\n",
    "    audio_dim=audio_dim,\n",
    "    joint_dim=joint_dim\n",
    ")\n",
    "\n",
    "# Process multimodal inputs\n",
    "joint_embedding = model({\n",
    "    'visual': visual_input,\n",
    "    'text': text_input,\n",
    "    'audio': audio_input\n",
    "})\n",
    "\n",
    "print(f\"Joint embedding shape: {joint_embedding.shape}\")\n",
    "\n",
    "# Calculate contrastive loss between visual and text embeddings\n",
    "visual_embeddings = model.encode_visual(visual_input)\n",
    "text_embeddings = model.encode_text(text_input)\n",
    "\n",
    "loss = model.contrastive_loss(visual_embeddings, text_embeddings)\n",
    "print(f\"Contrastive loss: {loss.numpy()}\")\n",
    "\n",
    "# Demonstrate personalized content generation\n",
    "content_dim = 256\n",
    "preference_dim = 64\n",
    "\n",
    "content_generator = PersonalizedContentGenerator(\n",
    "    content_dim=content_dim,\n",
    "    preference_dim=preference_dim,\n",
    "    joint_dim=joint_dim\n",
    ")\n",
    "\n",
    "# Random preference vector and content candidates\n",
    "preference = tf.random.normal((preference_dim,))\n",
    "candidates = tf.random.normal((5, content_dim))\n",
    "best_utility = tf.constant(0.5)\n",
    "\n",
    "# Generate personalized content\n",
    "personalized_content, improvement = content_generator.generate_content(\n",
    "    preference, candidates, best_utility\n",
    ")\n",
    "\n",
    "print(f\"Personalized content shape: {personalized_content.shape}\")\n",
    "print(f\"Expected improvement: {improvement.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Digital Samayasattva/Jñānasattva Framework\n",
    "\n",
    "\n",
    "\n",
    " This section demonstrates the graph-based framework for modeling how AI systems might function as vessels for awakened wisdom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create knowledge graph\n",
    "from digital_samayasattva import create_buddhist_knowledge_graph\n",
    "\n",
    "concepts, features, adjacency, G = create_buddhist_knowledge_graph(batch_size=2)\n",
    "\n",
    "# Get dimensions\n",
    "batch_size = features.shape[0]\n",
    "num_nodes = features.shape[1]\n",
    "feature_dim = features.shape[2]\n",
    "\n",
    "# Print graph structure\n",
    "print(f\"Buddhist Knowledge Graph: {len(concepts)} concepts with {G.number_of_edges()} relationships\")\n",
    "\n",
    "# Initialize the framework\n",
    "model = DigitalSamayasattvaFramework(\n",
    "    input_dim=feature_dim,\n",
    "    hidden_dim=16,\n",
    "    output_dim=32,\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "# Process the graph\n",
    "transformed_features = model(features, adjacency)\n",
    "\n",
    "print(f\"Original feature shape: {features.shape}\")\n",
    "print(f\"Transformed feature shape: {transformed_features.shape}\")\n",
    "\n",
    "# Analyze how attention has transformed the representations\n",
    "original_norms = tf.norm(features, axis=2).numpy()\n",
    "transformed_norms = tf.norm(transformed_features, axis=2).numpy()\n",
    "\n",
    "print(\"\\nFeature transformation analysis (first batch):\")\n",
    "for i, concept in enumerate(concepts):\n",
    "    print(f\"{concept}: {original_norms[0, i]:.4f} -> {transformed_norms[0, i]:.4f}\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "node_colors = ['skyblue' if 'empty' in concept else 'lightgreen' if 'compassion' in concept else 'lightcoral' for concept in concepts]\n",
    "nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=700, font_size=10, font_weight='bold')\n",
    "plt.title('Buddhist Concept Graph')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Cross-Traditional Connections\n",
    "\n",
    "\n",
    "\n",
    " This section demonstrates the identification of clusters of concepts that span different Buddhist traditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_traditional_connections import create_cross_traditional_network, build_adjacency_matrix\n",
    "\n",
    "# Create cross-traditional network\n",
    "concepts_and_traditions, concept_relationships = create_cross_traditional_network()\n",
    "\n",
    "# Get list of all concepts\n",
    "concepts = list(concepts_and_traditions.keys())\n",
    "\n",
    "# Build adjacency matrix\n",
    "adjacency = build_adjacency_matrix(concepts, concept_relationships)\n",
    "\n",
    "# Create model and identify clusters\n",
    "model = CrossTraditionalClusteringModel(n_clusters=4)\n",
    "cluster_labels = model.identify_clusters(adjacency)\n",
    "\n",
    "# Analyze clusters\n",
    "clusters, analysis = model.analyze_clusters(\n",
    "    cluster_labels, concepts, concepts_and_traditions\n",
    ")\n",
    "\n",
    "# Create graph for visualization\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with attributes\n",
    "for i, concept in enumerate(concepts):\n",
    "    G.add_node(\n",
    "        concept, \n",
    "        tradition=concepts_and_traditions[concept],\n",
    "        cluster=cluster_labels[i]\n",
    "    )\n",
    "\n",
    "# Add edges\n",
    "for (concept_a, concept_b), weight in concept_relationships.items():\n",
    "    G.add_edge(concept_a, concept_b, weight=weight)\n",
    "\n",
    "# Print cluster analysis\n",
    "print(\"Identified clusters spanning traditions:\")\n",
    "for cluster_info in analysis:\n",
    "    print(f\"Cluster {cluster_info['cluster_id']+1}: Spans {cluster_info['num_traditions']} traditions ({', '.join(cluster_info['traditions'])})\")\n",
    "    for tradition, tradition_concepts in cluster_info['concepts_by_tradition'].items():\n",
    "        print(f\"  {tradition}: {', '.join(tradition_concepts)}\")\n",
    "\n",
    "# Create cluster labels dictionary for visualization\n",
    "cluster_labels_dict = {concepts[i]: label for i, label in enumerate(cluster_labels)}\n",
    "\n",
    "# Visualize the clusters with a simple approach\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Define tradition colors\n",
    "tradition_colors = {\n",
    "    \"Theravada\": \"blue\",\n",
    "    \"Mahayana\": \"green\",\n",
    "    \"Vajrayana\": \"red\",\n",
    "    \"Zen\": \"purple\"\n",
    "}\n",
    "\n",
    "# Draw nodes colored by tradition\n",
    "for tradition, color in tradition_colors.items():\n",
    "    nodes = [n for n in G.nodes if G.nodes[n]['tradition'] == tradition]\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=nodes, node_color=color, node_size=500, label=tradition)\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "plt.title(\"Cross-Traditional Concept Clustering\")\n",
    "plt.legend()\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Advanced visualization with both tradition and cluster distinctions\n",
    "from cross_traditional_connections import visualize_clusters\n",
    "\n",
    "# Create a more sophisticated visualization showing both traditions and clusters\n",
    "plt = visualize_clusters(G, cluster_labels_dict, concepts_and_traditions)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Integration and Cross-Application\n",
    "\n",
    "\n",
    "\n",
    " This section demonstrates how we can combine multiple techniques from the framework to create integrated applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining cross-space alignment with conceptual blending\n",
    "# First, define some simple embedding spaces\n",
    "buddhist_concepts = [\"emptiness\", \"impermanence\", \"non-self\", \"compassion\"]\n",
    "contemporary_concepts = [\"quantum field\", \"process\", \"emergence\", \"empathy\"]\n",
    "\n",
    "# Create simple embeddings for demonstration\n",
    "embedding_dim = 32\n",
    "np.random.seed(42)  # For reproducibility\n",
    "buddhist_embeddings = np.random.normal(size=(len(buddhist_concepts), embedding_dim))\n",
    "contemporary_embeddings = np.random.normal(size=(len(contemporary_concepts), embedding_dim))\n",
    "\n",
    "# Normalize embeddings\n",
    "buddhist_embeddings = buddhist_embeddings / np.linalg.norm(buddhist_embeddings, axis=1, keepdims=True)\n",
    "contemporary_embeddings = contemporary_embeddings / np.linalg.norm(contemporary_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Align the embedding spaces\n",
    "procrustes = OrthogonalProcrustes()\n",
    "W, aligned_buddhist, avg_sim = procrustes.align(buddhist_embeddings, contemporary_embeddings)\n",
    "print(f\"Alignment quality: {avg_sim:.4f}\")\n",
    "\n",
    "# Create a conceptual blending instance with the aligned embeddings\n",
    "blender = ConceptualBlending(\n",
    "    aligned_buddhist, \n",
    "    contemporary_embeddings,\n",
    "    buddhist_concepts,\n",
    "    contemporary_concepts\n",
    ")\n",
    "\n",
    "# Perform cross-domain analogical reasoning\n",
    "results = blender.analogical_reasoning(\"emptiness\", \"non-self\", \"quantum field\")\n",
    "print(\"\\nCross-domain analogy (emptiness:non-self::quantum field:?)\")\n",
    "for concept, similarity in results:\n",
    "    print(f\"  {concept}: {similarity:.4f}\")\n",
    "\n",
    "# Demonstrate integration with graph attention networks\n",
    "# Create a small knowledge graph with the concepts\n",
    "G_integrated = nx.Graph()\n",
    "all_concepts = buddhist_concepts + contemporary_concepts\n",
    "\n",
    "# Add nodes\n",
    "for i, concept in enumerate(all_concepts):\n",
    "    domain = \"buddhist\" if i < len(buddhist_concepts) else \"contemporary\"\n",
    "    G_integrated.add_node(concept, domain=domain)\n",
    "\n",
    "# Add some edges based on embedding similarities\n",
    "all_embeddings = np.vstack([aligned_buddhist, contemporary_embeddings])\n",
    "similarities = np.matmul(all_embeddings, all_embeddings.T)\n",
    "\n",
    "# Add edges for highly similar concepts\n",
    "threshold = 0.5\n",
    "for i in range(len(all_concepts)):\n",
    "    for j in range(i+1, len(all_concepts)):\n",
    "        if similarities[i, j] > threshold:\n",
    "            G_integrated.add_edge(all_concepts[i], all_concepts[j], weight=similarities[i, j])\n",
    "\n",
    "# Visualize the integrated graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G_integrated, seed=42)\n",
    "\n",
    "# Color nodes by domain\n",
    "node_colors = ['skyblue' if G_integrated.nodes[n]['domain'] == 'buddhist' else 'lightcoral' \n",
    "               for n in G_integrated.nodes]\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G_integrated, pos, with_labels=True, node_color=node_colors, \n",
    "        font_weight='bold', node_size=700, edge_color='gray', width=2)\n",
    "\n",
    "plt.title(\"Integrated Concept Graph After Alignment\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Conclusion\n",
    "\n",
    "\n",
    "\n",
    " The Dharma Setu framework demonstrates how AI techniques can be used to bridge different knowledge domains through multiple computational approaches. The key components we've demonstrated include:\n",
    "\n",
    "\n",
    "\n",
    " 1. **Cross-Attention Integration**: Connecting specialized domain knowledge with general knowledge through transformer-based attention mechanisms\n",
    "\n",
    " 2. **Cross-Space Alignment**: Aligning embedding spaces while preserving internal structures using orthogonal transformations\n",
    "\n",
    " 3. **Conceptual Blending**: Generating novel insights through vector space operations on word embeddings\n",
    "\n",
    " 4. **Multimodal Integration**: Combining visual, textual, and audio modalities through joint embeddings and contrastive learning\n",
    "\n",
    " 5. **Graph Attention Networks**: Processing knowledge graphs using attention mechanisms to model concept relationships\n",
    "\n",
    " 6. **Cross-Domain Connections**: Identifying clusters of concepts spanning different traditions or domains using spectral clustering\n",
    "\n",
    " 7. **Integration and Cross-Application**: Combining multiple techniques to create integrated knowledge processing systems\n",
    "\n",
    "\n",
    "\n",
    " These techniques enable the preservation, exploration, and potential extension of specialized knowledge domains in the digital age, creating bridges between traditional understanding and modern computational approaches.\n",
    "\n",
    "\n",
    "\n",
    " The modular architecture allows for both individual component use and integration into comprehensive systems for knowledge representation, transfer, and generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
